# PCA
Principal Component Analysis.
- Dimensionality reduction algorithm이라고도 불린다.
- Eigenvalues와 eigenvectors를 활용한다.
### 예시
- 2차원의 데이터가 있다고 하자.
- 데이터들의 특징을 최대한 반영해서 선형방정식을 구했다.
- 이제 이 선형방정식을 1차원의 방정식으로서 활용하는게 PCA다(차원축소)
# Linear Transformations
### Rank의 변화
변환 전의 rank=2일 때,
- 변환 시키는 행렬이 Non-singular인 경우 linear transformation의 결과 rank=2
- 변환 시키는 행렬이 Singular인 경우 linear transformation의 결과 rank=1 or 0

- Linear transformation을 한 이미지의 차원을 확인하면 rank의 변화를 추적할 수 있다.
### Determinant of Linear Transformation
- Linear Transformation 행렬의 행렬식 값 = 기저벡터를 선형변환 시켰을 때 그려지는 평행사변형의 '면적'
	- 판별식 값이 마이너스여도 상관없다.
	- 그저 벡터를 더하는 순서가 바뀐 것 뿐이다.
	- Singular/Non-singular 판별에 무리가 없다.
# Determinant
$$\huge det(AB)=det(A)det(B)$$
$$\huge det(A^{-1})=\frac{1}{det(A)}$$
